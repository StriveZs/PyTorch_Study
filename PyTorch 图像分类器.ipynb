{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Image Classifier\n",
    "通常来说，当你处理图像，文本，语音或者视频数据时，你可以使用标准python包将数据加载成numpy数组格式，然后将这个数组转换成torch.Tensor。\n",
    "\n",
    "- 对于图像，可以使用Pillow，OpenCV\n",
    "- 对于语音，可以使用scipy，librosa\n",
    "- 对于文本，可以直接用Python或Cypthon基础数据加载模块，或者用NLTK和SpaCy。\n",
    "\n",
    "特别是对于视觉，我们已经创建了一个叫做totchvision的包，**该包含有支持加载类似Imagenet, MINIST 等公共数据集的数据加载模块 torchvision.datasets 和支持家在图像数据转换模块 torch.utils.data.DataLoader**。\n",
    "\n",
    "这提供了极大地便利，并且避免了编写样板代码。  \n",
    "\n",
    "接下来，我们将使用CIFAR10数据集，它包含十个类别：'airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'。CIFAR-10中的图像尺寸为3×32×32，也就是RGB的3层的颜色通道，每层通道内的尺寸为32×32.由于是二维图像，图像维度为(3,32,32)。\n",
    "\n",
    "![figure1](https://gitee.com/zyp521/upload_image/raw/master/pU83wM.png)\n",
    "\n",
    "## 训练一个图像分类器\n",
    "我们将按次序做如下几步：\n",
    "- 使用torchvision加载并且归一化CIFAR10的训练和测试数据集\n",
    "- 定义一个卷积神经网络\n",
    "- 定义一个损失函数\n",
    "- 在训练样本数据上训练网络\n",
    "- 在测试样本数据上测试网络\n",
    "\n",
    "### 数据处理\n",
    "加载并归一化CIFAR10使用torchvision，用它来加载CIFAR10数据非常简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision数据集的输出是范围在[0,1]之间的PILImage，我们将他们转换成归一化范围为[-1,1]之间的张量Tensors。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b967e7adcb04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     [transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 数据集下载\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/datasets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# 数据加载到Dataloader，batch_size=4，worker=2, shuffle为随机排序\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Files already downloaded and verified'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mmakedir_exist_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# downloads file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mmakedir_exist_ok\u001b[0;34m(dirpath)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEXIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-use/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/datasets'"
     ]
    }
   ],
   "source": [
    "# 步骤整合，将转换为tensor和正则化整合到一起\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "# 数据集下载\n",
    "trainset = torchvision.datasets.CIFAR10(root=os.path.join('/datasets'),train=True,download=True,transform=transform)\n",
    "# 数据加载到Dataloader，batch_size=4，worker=2, shuffle为随机排序\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True,num_workers=1)\n",
    "# 测试集下载\n",
    "testset = torchvision.datasets.CIFAR10(root=os.path.join('/dataset'),train=False,download=True,transform=transform)\n",
    "# 测试集加载\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=4,shuffle=False,num_workers=1)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面来展示一下其中的一些训练图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-adfc2f3392c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# get some random training image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load trainload to iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image(img):\n",
    "    img = img / 2 + 0.5\n",
    "    img = np.array(img)\n",
    "    plt.imshow(np.transpose(img,(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training image\n",
    "dataiter = iter(trainloader) # load trainload to iteration\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(labels[0]) # labels[0]对应的是序号\n",
    "# show images\n",
    "# make_grid的作用是将若干幅图像拼成一幅图像。其中padding的作用就是子图像与子图像之间的pad有多宽。\n",
    "show_image(torchvision.utils.make_grid(images,padding=4))\n",
    "# print label\n",
    "print(' '.join('%s' %classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建网络模型\n",
    "将之前写好的卷积神经网络进行修改，改为能够使用三通道的图片的卷积神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(3,6,5) # input: 3 channels output: 6  filter:5×5\n",
    "        self.conv2 = nn.Conv2d(6,16,5) # input: 6 output: 16\n",
    "        # MaxPooling\n",
    "        self.pool1 = nn.MaxPool2d(2,2) # 最大池化层\n",
    "        self.pool2 = nn.MaxPool2d(2,2) # 最大池化层\n",
    "        # Fully Connection Layers\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10) # 最后的10根据类的个数决定, 这里我们数据集包含了10个类\n",
    "        \n",
    "    def num_flat_features(self,x):\n",
    "        \"\"\"\n",
    "        number of feature\n",
    "        \n",
    "        x:\n",
    "        \"\"\"\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # Max pooling over a (2,2) window\n",
    "        # 过程说明:输入为(1,3,32,32)的向量，经过第一层卷积网络后得到维度为(4,6,28,28)的向量，然后经过2×2的池化，得到(4,6,14,14)的向量\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        # If the size is a square you can onlu specify a single number\n",
    "        x = self.pool2(F.relu(self.conv2(x))) # 经过第二次卷积和池化后得到(4,16,5,5)的向量\n",
    "        # flatted\n",
    "        x = x.view(-1,self.num_flat_features(x)) #偏平化操作得到(4,16*5*5)=（4，400）的向量\n",
    "        # activate function\n",
    "        x = F.relu(self.fc1(x)) # 通过第一层全连接层(4,400)变为(4，120)\n",
    "        x = F.relu(self.fc2(x)) # 通过第二次全连接层(4,120)变为（4,84）\n",
    "        x = self.fc3(x) # 通过最后一层全连接层(4,84)变为(14,10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数和优化器\n",
    "让我们使用**分类交叉熵Cross-Entropy**作为损失函数，动量SGD做优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # criterion\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练网络\n",
    "我们只需要在数据迭代器上循环传给网络和优化器，输入就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net training parameters\n",
    "epochs = 2\n",
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader,0):\n",
    "        images, reference = data\n",
    "        # initial parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward\n",
    "        hypothesis = net(images)\n",
    "        # compute loss\n",
    "        loss = criterion(hypothesis,reference)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item() # 累加loss\n",
    "        # 每2000个块打印一次 loss平均值\n",
    "        if i % 2000 == 1999:\n",
    "            print('Epoch[{0}][{1}/{2}]\\t'\n",
    "                  'Loss-{loss_mean:.5f}'.format(epoch,i,len(trainloader),loss_mean=running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finish training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在测试集上测试\n",
    "我们将用神经网络的输出作为预测的类标来检查网络的预测性能，用样本的真实标签来校对。如果预测试正确的，我们将样本添加到正确预测的列表中。\n",
    "#### 简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training image\n",
    "dataiter = iter(testloader) # load trainload to iteration\n",
    "images, reference = dataiter.next()\n",
    "\n",
    "# show images\n",
    "# make_grid的作用是将若干幅图像拼成一幅图像。其中padding的作用就是子图像与子图像之间的pad有多宽。\n",
    "show_image(torchvision.utils.make_grid(images,padding=4))\n",
    "# print label\n",
    "print('Reference:'+' '.join('%s' %classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入到网络中，得到预测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = net(images)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出是预测与十个类的近似程度(softmax)，与某一个类的近似程度越高，网络就跃认为图像属于该类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, prediences = torch.max(hypothesis,1) # select the max value\n",
    "print(prediences)\n",
    "print('Predicted:' , ' '.join('%5s' %classes[prediences[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们将网络应用到整个测试集上，并且计算准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 关闭梯度追踪\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, references = data\n",
    "        outputs = net(images)\n",
    "        _, hypothesis = torch.max(outputs,1)\n",
    "        total += references.size(0)\n",
    "        correct += (hypothesis == references).sum().item() # 添加item将tensor元素提取出来\n",
    "\n",
    "print('Acuuracy of the network on the 10000 test images: %d%%' %(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来看一下网络对不同种类预测的正确率(共10种)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_total = torch.zeros(10,dtype=torch.float)\n",
    "class_correct = torch.zeros(10,dtype=torch.float)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, references = data\n",
    "        outputs = net(images)\n",
    "        _, hypothesis = torch.max(outputs,1)\n",
    "        temp = (references == hypothesis).squeeze() # 将对比结果创建为tensor存储，由True和False组成\n",
    "        for i in range(4):\n",
    "            reference = references[i]\n",
    "            add_num = 1\n",
    "            if temp[i] == False:\n",
    "                add_num = 0\n",
    "            class_correct[reference] += add_num\n",
    "            class_total[reference] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of {cla} : {accur:.2f}%'.format(cla=classes[i],accur=100*class_correct[i]/class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU训练\n",
    "如果你的电脑有英伟达的显卡，并且配置好了CUDA，以及PyTorch下载CUDA对应把进本才可以使用。下面是将首页被定义为首选使用GPU计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于我电脑是只有CPU，所以接下来所有的代码均是在CPU上运行的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device) # 网络使用cpu计算 如果你是GPU则是使用GPU计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是GPU设备的话，会有相关方法递归的遍历所有模块，并将它们的参数和缓冲器转换为CUDA张量。  \n",
    "**记住你也必须在每一步骤中向GPU发送输入和目标**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, references = images.to(device),references.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的网络规模很大的情况，GPU计算相对于CPU计算的加速效果十分明显。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于GPU计算的好话，你需要将模型放到GPU中：  \n",
    "```\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "然后，你可以复制所有的张量到GPU中：  \n",
    "```\n",
    "tensor = tensor.to(device)\n",
    "```\n",
    "\n",
    "**注意**:只是调用tensor.to(device) 返回一个新的能够在GPU上计算的tensor，而不是重写。  \n",
    "\n",
    "PyTorch默认只会使用一个GPU。通过使用DataParallel让你的模型并行运行，你可以在很容易的在多GPU上运行你的操作。  \n",
    "```\n",
    "model = nn.DataParallel(model)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-use",
   "language": "python",
   "name": "pytorch-use"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
